# ğŸ§  TF_Predictor Architecture Guide

## Overview
`TimeSeriesPredictor` is the core abstract base class for all time series prediction in tf_predictor. It handles data preprocessing, model training, prediction, and evaluation with support for multi-target, multi-horizon, and group-based operations.

---

## ğŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TimeSeriesPredictor                           â”‚
â”‚                    (Abstract Base Class)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Data Pipeline  â”‚  â”‚ Model Training â”‚  â”‚ Prediction &     â”‚ â”‚
â”‚  â”‚                â”‚  â”‚                â”‚  â”‚ Evaluation       â”‚ â”‚
â”‚  â”‚ â€¢ Feature Eng  â”‚  â”‚ â€¢ fit()        â”‚  â”‚ â€¢ predict()      â”‚ â”‚
â”‚  â”‚ â€¢ Scaling      â”‚  â”‚ â€¢ Validation   â”‚  â”‚ â€¢ evaluate()     â”‚ â”‚
â”‚  â”‚ â€¢ Sequencing   â”‚  â”‚ â€¢ Early Stop   â”‚  â”‚ â€¢ Metrics        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Complete Data Flow (REFACTORED - Oct 2025)

### Training Flow (fit)

```
User Data (Raw DataFrame)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. prepare_data(fit_scaler=True, store=False)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â–º Step 1: _create_base_features()
    â”‚   â€¢ Domain-specific features (overridable)
    â”‚   â€¢ Time-series features (automatic cyclical encoding)
    â”‚   â€¢ Sorts by group+time if group_column exists
    â”‚
    â”œâ”€â–º Step 2: create_shifted_targets()
    â”‚   â€¢ Creates target_h1, target_h2, ..., target_hN
    â”‚   â€¢ Removes rows with NaN
    â”‚
    â”œâ”€â–º Step 3: SKIP STORAGE (store_for_evaluation=False)
    â”‚
    â”œâ”€â–º Step 4: _encode_categorical_features()
    â”‚   â€¢ Label encoding for categorical columns
    â”‚
    â”œâ”€â–º Step 5: _determine_numerical_columns()
    â”‚   â€¢ Auto-detect feature columns
    â”‚   â€¢ Exclude targets, categoricals, shifted targets
    â”‚
    â”œâ”€â–º Step 6: _scale_features_single/grouped()
    â”‚   â€¢ Feature scaling: One scaler for all features
    â”‚   â€¢ Target scaling: PER-HORIZON â­
    â”‚     - close_target_h1 â†’ StandardScaler #1
    â”‚     - close_target_h2 â†’ StandardScaler #2
    â”‚     - close_target_h3 â†’ StandardScaler #3
    â”‚
    â””â”€â–º Step 7: _create_sequences()
        â€¢ Sliding window sequences
        â€¢ Separate numerical (3D) and categorical (2D) tensors
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Training Loop in fit()                            â”‚
â”‚    â€¢ Mini-batch training                              â”‚
â”‚    â€¢ Forward pass â†’ Loss â†’ Backward â†’ Update          â”‚
â”‚    â€¢ Validation after each epoch                      â”‚
â”‚    â€¢ Early stopping monitoring                        â”‚
â”‚    â€¢ Per-horizon inverse transform for metrics        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
  Model Trained âœ“
```

### Prediction Flow (predict)

```
New Data (Raw DataFrame)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. prepare_data(fit_scaler=False, store=True) â­     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â–º Step 1: _create_base_features()
    â”‚   â€¢ Same feature engineering as training
    â”‚
    â”œâ”€â–º Step 2: create_shifted_targets()
    â”‚   â€¢ Creates shifted targets
    â”‚
    â”œâ”€â–º Step 3: STORE FOR EVALUATION â­â­â­
    â”‚   â€¢ Store df with UNENCODED categorical values
    â”‚   â€¢ Store df with UNSCALED numerical values
    â”‚   â€¢ Store df with shifted target columns
    â”‚   â€¢ This is used for extracting actuals during evaluation
    â”‚   â€¢ Fixes 100% MAPE bug (dataframe alignment issue)
    â”‚
    â”œâ”€â–º Step 4: _encode_categorical_features()
    â”‚   â€¢ Uses EXISTING encoders (no fitting)
    â”‚
    â”œâ”€â–º Step 5: _determine_numerical_columns()
    â”‚   â€¢ Uses cached column lists
    â”‚
    â”œâ”€â–º Step 6: _scale_features_single/grouped()
    â”‚   â€¢ Uses EXISTING scalers (no fitting)
    â”‚   â€¢ Per-horizon target scalers
    â”‚
    â””â”€â–º Step 7: _create_sequences()
        â€¢ Same sequence structure as training
    â”‚
    â–¼
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Model Forward Pass                                â”‚
â”‚    â€¢ model(X) â†’ predictions_scaled                    â”‚
â”‚    â€¢ Predictions in scaled space                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Inverse Transform                                 â”‚
â”‚    â€¢ Unscale predictions back to original space       â”‚
â”‚    â€¢ Uses appropriate scaler(s) per target/group      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
  Predictions (Original Scale) âœ“
```

---

## ğŸ”§ Key Methods Deep Dive

### 1. **`__init__()` - Initialization**

```
Purpose: Set up the predictor with configuration
Input:
  - target_column: str or List[str]  (what to predict)
  - sequence_length: int             (lookback window)
  - prediction_horizon: int          (steps ahead)
  - group_column: Optional[str]      (for multi-entity data)
  - **ft_kwargs                      (model hyperparameters)

Creates:
  - Scalers (feature + target)
  - Model architecture
  - Training history tracking
```

### 2. **`create_features()` - Abstract Method**

```
Purpose: Domain-specific feature engineering (USER IMPLEMENTS THIS)
Input: Raw DataFrame
Output: DataFrame with engineered features

Example Implementation:
  - Add technical indicators (for stocks)
  - Add lag features
  - Add rolling statistics
  - Create shifted targets using create_shifted_targets()
```

### 3. **`prepare_features()` - Feature Pipeline**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  prepare_features()                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  1. Sort by group + time (if group_column exists)    â”‚
â”‚     â†“                                                 â”‚
â”‚  2. Call user's create_features()                    â”‚
â”‚     â†“                                                 â”‚
â”‚  3. Identify feature columns                         â”‚
â”‚     â€¢ Exclude target columns                         â”‚
â”‚     â€¢ Exclude shifted targets (_target_h*)           â”‚
â”‚     â€¢ Only numeric columns                           â”‚
â”‚     â†“                                                 â”‚
â”‚  4. Scale features                                   â”‚
â”‚     â€¢ Single-group: _scale_features_single()         â”‚
â”‚     â€¢ Multi-group: _scale_features_grouped()         â”‚
â”‚     â†“                                                 â”‚
â”‚  5. Cache result (optional)                          â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. **Scaling Methods**

#### `_scale_features_single()` - No Grouping

```
Input: DataFrame with features
Process:
  if fit_scaler:
      self.scaler.fit(features)
  features_scaled = self.scaler.transform(features)
Output: DataFrame with scaled features
```

#### `_scale_features_grouped()` - With Grouping

```
For each group in data:
    if fit_scaler:
        self.group_feature_scalers[group] = StandardScaler()
        self.group_feature_scalers[group].fit(group_data)
    group_data_scaled = self.group_feature_scalers[group].transform(group_data)

Concatenate all groups back together
```

### 5. **`prepare_data()` - Sequence & Target Preparation**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     prepare_data()                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  Route based on configuration:                           â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ group_column       â”‚  â”‚ No group_column          â”‚   â”‚
â”‚  â”‚ specified?         â”‚  â”‚                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                          â”‚                   â”‚
â”‚           â–¼                          â–¼                   â”‚
â”‚  _prepare_data_grouped()   _prepare_data_single()       â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Both methods do:
  1. Create sequences: create_input_variable_sequence()
  2. Extract targets from DataFrame (after sequence_length offset)
  3. Scale targets using appropriate scaler(s)
  4. Return (X_tensor, Y_tensor)
```

#### Target Scaling Logic

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Target Scaling Architecture              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  Single-Target                                   â”‚
â”‚  â”œâ”€ Single-Horizon: self.target_scaler          â”‚
â”‚  â””â”€ Multi-Horizon:  self.target_scaler (shared) â”‚
â”‚                                                  â”‚
â”‚  Multi-Target                                    â”‚
â”‚  â”œâ”€ Single-Horizon: self.target_scalers_dict    â”‚
â”‚  â”‚                   {'close': scaler1,         â”‚
â”‚  â”‚                    'volume': scaler2}        â”‚
â”‚  â””â”€ Multi-Horizon:  self.target_scalers_dict    â”‚
â”‚                     {'close': scaler1,  â† sharedâ”‚
â”‚                      'volume': scaler2} â† sharedâ”‚
â”‚                                                  â”‚
â”‚  Group-Based                                     â”‚
â”‚  â””â”€ self.group_target_scalers                   â”‚
â”‚     {'AAPL': {'close': scaler, 'volume': scaler}â”‚
â”‚      'MSFT': {'close': scaler, 'volume': scaler}â”‚
â”‚                                                  â”‚
â”‚  KEY: One scaler per variable (not per horizon) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6. **`_prepare_data_grouped()` - Group-based Preparation**

```
For each group (e.g., AAPL, MSFT, GOOGL):
    1. Extract group data
    2. Check if group has enough data (> sequence_length)
    3. Create sequences for this group
    4. Extract targets for this group
    5. Scale targets using group-specific scaler
    6. Track group membership for each sequence

Concatenate all groups:
    - All sequences stacked vertically
    - All targets stacked vertically
    - Group indices tracked for later inverse scaling
```

### 7. **`fit()` - Training Loop**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Training Loop                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  Prepare Training Data:                               â”‚
â”‚    X_train, y_train = prepare_data(train_df, fit=True)â”‚
â”‚                                                        â”‚
â”‚  Prepare Validation Data (if provided):               â”‚
â”‚    X_val, y_val = prepare_data(val_df, fit=False)     â”‚
â”‚                                                        â”‚
â”‚  Initialize Model:                                     â”‚
â”‚    FT-Transformer or CSN-Transformer                   â”‚
â”‚    â€¢ Input size = number of features                   â”‚
â”‚    â€¢ Output size = num_targets * prediction_horizon    â”‚
â”‚                                                        â”‚
â”‚  For each epoch:                                       â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚    â”‚  For each batch:                    â”‚           â”‚
â”‚    â”‚    1. Forward pass                  â”‚           â”‚
â”‚    â”‚    2. Compute loss                  â”‚           â”‚
â”‚    â”‚    3. Backward pass                 â”‚           â”‚
â”‚    â”‚    4. Update weights                â”‚           â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                        â”‚
â”‚    Validation (every epoch):                          â”‚
â”‚      - Compute val_loss                               â”‚
â”‚      - Inverse transform predictions                  â”‚
â”‚      - Calculate MAE & MAPE metrics                   â”‚
â”‚      - Print progress (verbose mode)                  â”‚
â”‚                                                        â”‚
â”‚    Early Stopping:                                    â”‚
â”‚      - Track best validation loss                     â”‚
â”‚      - Stop if no improvement for 'patience' epochs   â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8. **`predict()` - Make Predictions**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Prediction Flow                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  1. prepare_features(df, fit_scaler=False)            â”‚
â”‚     â€¢ Use EXISTING scalers                            â”‚
â”‚                                                        â”‚
â”‚  2. Create sequences (no targets needed)              â”‚
â”‚     â€¢ create_input_variable_sequence()                â”‚
â”‚                                                        â”‚
â”‚  3. Forward pass through model                        â”‚
â”‚     â€¢ predictions_scaled = model(X)                   â”‚
â”‚                                                        â”‚
â”‚  4. Inverse transform                                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚     â”‚  No grouping:                  â”‚               â”‚
â”‚     â”‚    Use self.target_scaler      â”‚               â”‚
â”‚     â”‚                                 â”‚               â”‚
â”‚     â”‚  With grouping:                â”‚               â”‚
â”‚     â”‚    For each group:             â”‚               â”‚
â”‚     â”‚      Use group's scaler        â”‚               â”‚
â”‚     â”‚                                 â”‚               â”‚
â”‚     â”‚  Multi-target:                 â”‚               â”‚
â”‚     â”‚    For each target:            â”‚               â”‚
â”‚     â”‚      Use target's scaler       â”‚               â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                        â”‚
â”‚  5. Return predictions in original scale              â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output Shapes:
  Single-target, single-horizon: (n_samples,)
  Single-target, multi-horizon:  (n_samples, horizons)
  Multi-target:                  Dict[target_name, array]
```

### 9. **`evaluate()` - Performance Metrics**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Evaluation Flow                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                        â”‚
â”‚  1. Get predictions: predict(df)                      â”‚
â”‚                                                        â”‚
â”‚  2. Get actual values                                 â”‚
â”‚     â€¢ Extract from original DataFrame                 â”‚
â”‚     â€¢ Align indices properly                          â”‚
â”‚       (account for sequence_length offset)            â”‚
â”‚                                                        â”‚
â”‚  3. Calculate metrics:                                â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚     â”‚  Standard Mode:                    â”‚           â”‚
â”‚     â”‚    â€¢ MSE (Mean Squared Error)      â”‚           â”‚
â”‚     â”‚    â€¢ RMSE (Root MSE)               â”‚           â”‚
â”‚     â”‚    â€¢ MAE (Mean Absolute Error)     â”‚           â”‚
â”‚     â”‚    â€¢ MAPE (Mean Abs % Error)       â”‚           â”‚
â”‚     â”‚    â€¢ RÂ² Score                      â”‚           â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                        â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚     â”‚  Per-Group Mode (per_group=True):  â”‚           â”‚
â”‚     â”‚    â€¢ Same metrics but per group    â”‚           â”‚
â”‚     â”‚    â€¢ Useful for multi-stock data   â”‚           â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                        â”‚
â”‚  4. Return metrics dictionary                         â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Usage Patterns

### Pattern 1: Single-Target, Single-Horizon

```python
# Simplest case: predict one variable, one step ahead
predictor = MyPredictor(
    target_column='close',
    sequence_length=10,
    prediction_horizon=1
)

predictor.fit(train_df, val_df, epochs=100)
predictions = predictor.predict(test_df)  # Shape: (n_samples,)
```

### Pattern 2: Single-Target, Multi-Horizon

```python
# Predict one variable, multiple steps ahead
predictor = MyPredictor(
    target_column='close',
    sequence_length=10,
    prediction_horizon=3  # Predict 1, 2, 3 steps ahead
)

predictor.fit(train_df, val_df, epochs=100)
predictions = predictor.predict(test_df)  # Shape: (n_samples, 3)
```

### Pattern 3: Multi-Target, Single-Horizon

```python
# Predict multiple variables, one step ahead
predictor = MyPredictor(
    target_column=['close', 'volume'],
    sequence_length=10,
    prediction_horizon=1
)

predictor.fit(train_df, val_df, epochs=100)
predictions = predictor.predict(test_df)
# Returns: {'close': array, 'volume': array}
```

### Pattern 4: Multi-Target, Multi-Horizon

```python
# Predict multiple variables, multiple steps ahead
predictor = MyPredictor(
    target_column=['close', 'volume'],
    sequence_length=10,
    prediction_horizon=3
)

predictor.fit(train_df, val_df, epochs=100)
predictions = predictor.predict(test_df)
# Returns: {
#   'close': array(shape=(n_samples, 3)),
#   'volume': array(shape=(n_samples, 3))
# }
```

### Pattern 5: Group-Based (Multi-Entity)

```python
# Predict across multiple stocks/entities
predictor = MyPredictor(
    target_column='close',
    sequence_length=10,
    prediction_horizon=1,
    group_column='symbol'  # AAPL, MSFT, GOOGL, etc.
)

# Training data has multiple symbols
predictor.fit(train_df, val_df, epochs=100)

# Predictions maintain group-specific scaling
predictions = predictor.predict(test_df)
```

---

## ğŸ”‘ Key Design Principles

### 1. **Separation of Concerns**

```
User's Responsibility:
  - create_features() implementation
  - Domain-specific feature engineering

tf_predictor's Responsibility:
  - Scaling
  - Sequencing
  - Training loop
  - Prediction
  - Evaluation
```

### 2. **Scaling Architecture**

```
Rule: One scaler per variable (shared across all horizons)

Why?
  - Consistent scale across time horizons
  - Easier to compare h1 vs h2 vs h3 predictions
  - More stable training
  - Correct inverse transformation

Example:
  close_target_h1, close_target_h2, close_target_h3
         â†“              â†“              â†“
       All use the same close_scaler
```

### 3. **Group-Based Operations**

```
When group_column is specified:
  - Each group gets its own scaler(s)
  - Prevents data leakage across groups
  - Sorting by [group, time] ensures temporal order
  - Predictions use group-specific scalers

Use cases:
  - Multi-stock prediction (group by symbol)
  - Multi-sensor data (group by sensor_id)
  - Multi-customer forecasting (group by customer_id)
```

### 4. **Caching Strategy**

```
Feature Cache:
  - Avoid recomputing features for same data
  - Hash based on: shape + columns + first row
  - Can be disabled: disable_feature_cache()
  - Cleared automatically or manually: clear_feature_cache()

Benefits:
  - Faster repeated calls with same data
  - Useful during experimentation
```

---

## ğŸ“ˆ Complete Example Walkthrough

### Scenario: Multi-Stock, Multi-Horizon Prediction

```python
# Setup
predictor = StockPredictor(
    target_column='close',
    sequence_length=10,
    prediction_horizon=3,
    group_column='symbol'
)

# Data structure
train_df:
  symbol  date        close   volume   ...
  AAPL    2023-01-01  150     1000000
  AAPL    2023-01-02  151     1100000
  ...
  MSFT    2023-01-01  250     800000
  MSFT    2023-01-02  251     850000
  ...
```

### Training Flow

```
1. prepare_features(train_df, fit_scaler=True)
   â”œâ”€ Sort by [symbol, date]
   â”œâ”€ create_features() adds indicators
   â”œâ”€ create_shifted_targets() adds:
   â”‚    close_target_h1, close_target_h2, close_target_h3
   â””â”€ Scale features per group:
        AAPL_scaler.fit(AAPL_data)
        MSFT_scaler.fit(MSFT_data)

2. prepare_data(train_df_processed, fit_scaler=True)
   For AAPL:
     â”œâ”€ create_input_variable_sequence() â†’ AAPL_sequences
     â”œâ”€ Extract targets: close_target_h1, h2, h3
     â””â”€ Scale with AAPL_target_scaler.fit()

   For MSFT:
     â”œâ”€ create_input_variable_sequence() â†’ MSFT_sequences
     â”œâ”€ Extract targets: close_target_h1, h2, h3
     â””â”€ Scale with MSFT_target_scaler.fit()

   Stack all: X_train, y_train

3. fit() training loop
   â”œâ”€ For each epoch:
   â”‚    â”œâ”€ Mini-batch training
   â”‚    â””â”€ Validation with metrics
   â””â”€ Early stopping if no improvement
```

### Prediction Flow

```
1. prepare_features(test_df, fit_scaler=False)
   â””â”€ Use EXISTING scalers (no fitting)

2. Create sequences (no targets needed)

3. model.forward(X_test) â†’ predictions_scaled

4. Inverse transform per group:
   For AAPL predictions:
     â””â”€ AAPL_target_scaler.inverse_transform()
   For MSFT predictions:
     â””â”€ MSFT_target_scaler.inverse_transform()

5. Return predictions in original scale
```

---

## ğŸ› ï¸ Helper Methods

### Model Persistence

```python
# Save trained model
predictor.save('model.pkl')

# Load trained model
predictor = TimeSeriesPredictor.load('model.pkl')
```

### Advanced Prediction

```python
# Predict with group information
predictions, group_indices = predictor.predict(
    test_df,
    return_group_info=True
)
# group_indices tells you which group each prediction belongs to
```

### Evaluation Options

```python
# Standard evaluation
metrics = predictor.evaluate(test_df)
# Returns: {'mse': ..., 'rmse': ..., 'mae': ..., 'mape': ..., 'r2': ...}

# Per-group evaluation
metrics_per_group = predictor.evaluate(test_df, per_group=True)
# Returns: {
#   'AAPL': {'mse': ..., 'mae': ..., ...},
#   'MSFT': {'mse': ..., 'mae': ..., ...}
# }
```

---

## ğŸ“ Summary

### Core Responsibilities

1. **Data Pipeline**: Feature engineering â†’ Scaling â†’ Sequencing
2. **Training**: Model training with validation and early stopping
3. **Prediction**: Forward pass â†’ Inverse scaling â†’ Return predictions
4. **Evaluation**: Calculate comprehensive performance metrics

### Supported Configurations

| Feature | Support |
|---------|---------|
| Single-target | âœ… |
| Multi-target | âœ… |
| Single-horizon | âœ… |
| Multi-horizon | âœ… |
| Group-based operations | âœ… |
| Feature caching | âœ… |
| Early stopping | âœ… |
| Model persistence | âœ… |

### Extension Points

- **`create_features()`**: Implement domain-specific feature engineering
- **Model architecture**: Can use FT-Transformer or CSN-Transformer
- **Hyperparameters**: Fully configurable via `**ft_kwargs`

