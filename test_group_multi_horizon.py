#!/usr/bin/env python3
"""
Test group-based scaling combined with multi-horizon predictions.

This test verifies that when using multiple symbols and multiple prediction horizons:
1. Per-symbol, per-horizon metrics are calculated correctly
2. CSV exports include symbol column and all horizons
3. Predictions maintain correct symbol-to-prediction mapping
"""

import pandas as pd
import numpy as np
from daily_stock_forecasting import StockPredictor

# Create synthetic multi-symbol, time series data
np.random.seed(42)

def create_multi_symbol_data(n_days=100):
    """Create synthetic data for multiple symbols with different price ranges."""
    symbols = ['AAPL', 'GOOGL', 'MSFT']
    all_data = []

    for symbol in symbols:
        # Different base prices for each symbol
        if symbol == 'AAPL':
            base_price = 150
        elif symbol == 'GOOGL':
            base_price = 2800
        else:  # MSFT
            base_price = 350

        # Generate dates
        dates = pd.date_range('2024-01-01', periods=n_days, freq='D')

        # Generate price data with trend and noise
        trend = np.linspace(0, 20, n_days)
        noise = np.random.normal(0, base_price * 0.02, n_days)
        prices = base_price + trend + noise

        # Create OHLCV data
        for i, date in enumerate(dates):
            price = prices[i]
            all_data.append({
                'date': date,
                'symbol': symbol,
                'open': price * 0.99,
                'high': price * 1.01,
                'low': price * 0.98,
                'close': price,
                'volume': np.random.randint(1000000, 5000000)
            })

    df = pd.DataFrame(all_data)
    return df

print("="*80)
print("TEST: Group-based Scaling + Multi-Horizon Predictions")
print("="*80)

# Step 1: Create data
print("\n1. Creating multi-symbol dataset...")
df = create_multi_symbol_data(n_days=200)
print(f"   Created data with {len(df)} rows")
print(f"   Symbols: {df['symbol'].unique()}")
print(f"   Date range: {df['date'].min()} to {df['date'].max()}")

# Show price ranges per symbol
print("\n   Price ranges per symbol:")
for symbol in df['symbol'].unique():
    symbol_data = df[df['symbol'] == symbol]
    print(f"   {symbol}: ${symbol_data['close'].min():.2f} - ${symbol_data['close'].max():.2f}")

# Step 2: Split data
print("\n2. Splitting data (60 train / 20 val / 20 test per symbol)...")
train_df = df[df['date'] < '2024-02-29'].copy()
val_df = df[(df['date'] >= '2024-02-29') & (df['date'] < '2024-03-20')].copy()
test_df = df[df['date'] >= '2024-03-20'].copy()

print(f"   Train: {len(train_df)} rows")
print(f"   Val: {len(val_df)} rows")
print(f"   Test: {len(test_df)} rows")

# Step 3: Initialize model with group_column and multi-horizon
print("\n3. Initializing StockPredictor with group_column='symbol' and prediction_horizon=3...")
model = StockPredictor(
    target_column='close',
    sequence_length=10,
    group_column='symbol',  # Enable group-based scaling
    prediction_horizon=3,    # Predict 3 steps ahead
    d_token=64,              # Small model for fast testing
    n_layers=2,
    n_heads=4,
    dropout=0.1,
    verbose=True
)

print(f"   Model initialized:")
print(f"   - Group column: {model.group_column}")
print(f"   - Prediction horizon: {model.prediction_horizon}")
print(f"   - Sequence length: {model.sequence_length}")

# Step 4: Train model
print("\n4. Training model (10 epochs for quick test)...")
model.fit(
    train_df,
    val_df=val_df,
    epochs=10,
    batch_size=16,
    learning_rate=0.001,
    patience=5,
    verbose=False  # Suppress epoch-by-epoch output
)

print("   âœ… Training completed!")
print(f"   Final train loss: {model.history['train_loss'][-1]:.6f}")
print(f"   Final val loss: {model.history['val_loss'][-1]:.6f}")

# Step 5: Make predictions with group info
print("\n5. Making predictions with group information...")
test_predictions, test_groups = model.predict(test_df, return_group_info=True)

print(f"   Predictions shape: {test_predictions.shape}")
print(f"   Expected: (n_samples, {model.prediction_horizon})")
print(f"   Number of group indices: {len(test_groups)}")
print(f"   Unique groups in predictions: {sorted(set(test_groups))}")

# Verify predictions per symbol
print("\n   Predictions per symbol:")
for symbol in sorted(set(test_groups)):
    symbol_count = sum(1 for g in test_groups if g == symbol)
    print(f"   {symbol}: {symbol_count} predictions")

# Step 6: Evaluate with per-group metrics
print("\n6. Evaluating with per_group=True...")
test_metrics = model.evaluate(test_df, per_group=True)

print("   âœ… Per-group evaluation completed!")
print(f"   Metric keys: {list(test_metrics.keys())}")

# Verify structure
assert 'overall' in test_metrics, "Missing 'overall' key in metrics"
assert 'AAPL' in test_metrics, "Missing 'AAPL' in metrics"
assert 'GOOGL' in test_metrics, "Missing 'GOOGL' in metrics"
assert 'MSFT' in test_metrics, "Missing 'MSFT' in metrics"

print("\n   Overall metrics structure:")
overall = test_metrics['overall']
print(f"   - Keys: {list(overall.keys())}")
assert 'overall' in overall, "Missing 'overall' in overall metrics"
assert 'horizon_1' in overall, "Missing 'horizon_1' in overall metrics"
assert 'horizon_2' in overall, "Missing 'horizon_2' in overall metrics"
assert 'horizon_3' in overall, "Missing 'horizon_3' in overall metrics"

print("\n   AAPL metrics structure:")
aapl_metrics = test_metrics['AAPL']
print(f"   - Keys: {list(aapl_metrics.keys())}")
assert 'overall' in aapl_metrics, "Missing 'overall' in AAPL metrics"
assert 'horizon_1' in aapl_metrics, "Missing 'horizon_1' in AAPL metrics"

# Print sample metrics
print("\n   ðŸ“Š Sample Metrics - Overall (All Symbols):")
overall_avg = test_metrics['overall']['overall']
print(f"   MAE: ${overall_avg.get('MAE', 0):.2f}")
print(f"   MAPE: {overall_avg.get('MAPE', 0):.2f}%")

print("\n   ðŸ“Š Sample Metrics - AAPL Horizon 1:")
aapl_h1 = test_metrics['AAPL']['horizon_1']
print(f"   MAE: ${aapl_h1.get('MAE', 0):.2f}")
print(f"   MAPE: {aapl_h1.get('MAPE', 0):.2f}%")

print("\n   ðŸ“Š Sample Metrics - GOOGL Horizon 1:")
googl_h1 = test_metrics['GOOGL']['horizon_1']
print(f"   MAE: ${googl_h1.get('MAE', 0):.2f}")
print(f"   MAPE: {googl_h1.get('MAPE', 0):.2f}%")

# Step 7: Test CSV export
print("\n7. Testing CSV export with symbol column...")
from daily_stock_forecasting.visualization.stock_charts import export_predictions_csv
from pathlib import Path
import tempfile

with tempfile.TemporaryDirectory() as tmpdir:
    csv_path = export_predictions_csv(model, train_df, test_df, tmpdir)
    print(f"   CSV exported to: {csv_path}")

    # Read and verify CSV
    csv_df = pd.read_csv(csv_path)
    print(f"   CSV shape: {csv_df.shape}")
    print(f"   CSV columns: {list(csv_df.columns)}")

    # Verify symbol column exists
    assert 'symbol' in csv_df.columns, "Symbol column missing from CSV!"
    print("   âœ… Symbol column present in CSV")

    # Verify horizon columns exist
    assert 'pred_h1' in csv_df.columns, "pred_h1 column missing!"
    assert 'pred_h2' in csv_df.columns, "pred_h2 column missing!"
    assert 'pred_h3' in csv_df.columns, "pred_h3 column missing!"
    print("   âœ… All horizon prediction columns present (pred_h1, pred_h2, pred_h3)")

    # Verify error columns exist
    assert 'error_h1' in csv_df.columns, "error_h1 column missing!"
    assert 'mape_h1' in csv_df.columns, "mape_h1 column missing!"
    print("   âœ… Error columns present for all horizons")

    # Show sample rows
    print("\n   Sample CSV rows:")
    print(csv_df[['date', 'symbol', 'actual', 'pred_h1', 'pred_h2', 'pred_h3', 'dataset']].head(6))

    # Verify symbols in CSV
    csv_symbols = sorted(csv_df['symbol'].unique())
    print(f"\n   Symbols in CSV: {csv_symbols}")
    assert csv_symbols == ['AAPL', 'GOOGL', 'MSFT'], "Symbol mismatch in CSV!"

    # Verify row counts per symbol
    print("\n   Rows per symbol:")
    for symbol in csv_symbols:
        symbol_count = len(csv_df[csv_df['symbol'] == symbol])
        print(f"   {symbol}: {symbol_count} rows")

print("\n" + "="*80)
print("âœ… ALL TESTS PASSED!")
print("="*80)
print("\nVerified:")
print("  âœ“ Group-based scaling works with multi-horizon predictions")
print("  âœ“ Per-symbol, per-horizon metrics are calculated correctly")
print("  âœ“ CSV export includes symbol column and all horizon predictions")
print("  âœ“ Predictions maintain correct symbol-to-prediction mapping")
print("  âœ“ Metrics structure is properly nested (symbol -> horizon -> metrics)")
