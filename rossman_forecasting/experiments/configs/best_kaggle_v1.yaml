# Best Kaggle Submission Config v1
# Purpose: Template for tuning final submission
# Use: python rossman_forecasting/main.py --experiment_config best_kaggle_v1

experiment:
  name: "best_kaggle_v1"
  description: "Final tuned configuration for Kaggle submission"

preprocessing:
  config: "competition_enhanced"
  max_stores: null  # Use all stores
  force_preprocess: false

model:
  model_type: "ft_transformer"
  d_token: 192
  n_layers: 4
  n_heads: 8
  pooling_type: "multihead_attention"
  sequence_length: 30  # Longer sequence to capture monthly patterns
  prediction_horizon: 1
  dropout: 0.15  # Slightly higher dropout for regularization
  scaler_type: "standard"

training:
  epochs: 150
  batch_size: 128
  learning_rate: 0.0003  # Lower learning rate for fine-tuning
  patience: 25
  val_ratio: 0.2

output:
  save_model: true
  export_predictions: true
  create_submission: true

notes: "Tuned for Kaggle submission - adjust hyperparameters based on validation RMSPE"
